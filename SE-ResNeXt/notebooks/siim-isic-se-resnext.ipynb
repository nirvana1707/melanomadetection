{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import imageio\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from PIL import Image, ImageFile\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import albumentations\n",
    "from albumentations.pytorch.transforms import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional\n",
    "import torch.nn as nn\n",
    "from torch.utils import model_zoo\n",
    "from albumentations.pytorch.transforms import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stratification:\n",
    "    def __init__(self,path_dir,num_splits):\n",
    "        self.input_path = path_dir\n",
    "        self.n_splits = num_splits\n",
    "        self.df = pd.read_csv(os.path.join(input_path,\"train.csv\"))\n",
    "        \n",
    "    def create_split(self):\n",
    "        self.df['kfold'] = -1\n",
    "        #Shuffling the csv file => to get a new shuffled dataframe\n",
    "        self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "        #Target value\n",
    "        y=self.df.target.values\n",
    "        #Why stratified - because we want the ratio of +ve:-ve samples to be the same\n",
    "        kf = model_selection.StratifiedKFold(n_splits=self.n_splits)\n",
    "        \n",
    "        kfold_df_dict = {}\n",
    "        \n",
    "        for fold_, (train_idx, val_idx) in enumerate(kf.split(X=self.df,y=y)):\n",
    "            df_temp = pd.read_csv(os.path.join(input_path,\"train.csv\"))\n",
    "            df_temp['kfold'] = -1\n",
    "            df_temp['dataset_type'] = 'train'\n",
    "            df_temp.loc[:,'kfold']=fold_\n",
    "            df_temp.loc[val_idx,'dataset_type'] = 'val'\n",
    "            kfold_df_dict[fold_]=df_temp\n",
    "        \n",
    "        df_comb_fold = pd.concat(kfold_df_dict[k] for (k,v) in kfold_df_dict.items())\n",
    "        \n",
    "        return df_comb_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"/kaggle/input/siim-isic-melanoma-classification\"\n",
    "num_splits = 10\n",
    "df_actual_train = pd.read_csv(\"/kaggle/input/siim-isic-melanoma-classification/train.csv\")\n",
    "df_kfold = stratification(input_path,num_splits).create_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_ResNext_Pytorch(torch.nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        #The super() function is used to give access to methods and properties of a parent or sibling class.\n",
    "        #The super() function returns an object that represents the parent class.\n",
    "        super(Model_ResNext_Pytorch,self).__init__()\n",
    "        #self.model = pretrainedmodels.__dict__[\"se_resnext50_32x4d\"]\n",
    "        self.model = torch.hub.load('pytorch/vision:v0.6.0', 'resnext50_32x4d', pretrained=True)\n",
    "        ## Changing the last layer\n",
    "        num_ftrs = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(num_ftrs, 1)\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    def forward(self,image,targets):\n",
    "        # Arguments should match your dataloader arguments wrt dataset being passed\n",
    "        # in this case it is image, targets\n",
    "        \n",
    "        #with torch.no_grad():\n",
    "        out = self.model(image)\n",
    "        #print(\"Printing output\")\n",
    "        #print(out)\n",
    "        loss = nn.BCEWithLogitsLoss()(\n",
    "            out, targets.reshape(-1,1).type_as(out)\n",
    "        )\n",
    "        # shape and datatype\n",
    "        return out,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationLoader:\n",
    "    def __init__(self, image_paths, targets, resize, augmentations):\n",
    "        self.image_paths = image_paths\n",
    "        self.targets = targets\n",
    "        self.resize = resize\n",
    "        self.augmentations = augmentations\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image = Image.open(self.image_paths[item])\n",
    "        targets = self.targets[item]\n",
    "        if self.resize is not None:\n",
    "            image = image.resize(\n",
    "                (self.resize[1], self.resize[0]), resample=Image.BILINEAR\n",
    "            )\n",
    "        image = np.array(image)\n",
    "        if self.augmentations is not None:\n",
    "            augmented = self.augmentations(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "        return {\n",
    "            \"image\": torch.tensor(image, dtype=torch.float),\n",
    "            \"targets\": torch.tensor(targets, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, mode=\"max\", delta=0.0001):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.mode = mode\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.delta = delta\n",
    "        if self.mode == \"min\":\n",
    "            self.val_score = np.Inf\n",
    "        else:\n",
    "            self.val_score = -np.Inf\n",
    "\n",
    "    def __call__(self, epoch_score, model, model_path):\n",
    "        if self.mode == \"min\":\n",
    "            score = -1.0 * epoch_score\n",
    "        else:\n",
    "            score = np.copy(epoch_score)\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(epoch_score, model, model_path)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(\n",
    "                \"EarlyStopping counter: {} out of {}\".format(\n",
    "                    self.counter, self.patience\n",
    "                )\n",
    "            )\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(epoch_score, model, model_path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, epoch_score, model, model_path):\n",
    "        if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:\n",
    "            print(\n",
    "                \"Validation score improved ({} --> {}). Saving model!\".format(\n",
    "                    self.val_score, epoch_score\n",
    "                )\n",
    "            )\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        self.val_score = epoch_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Engine:\n",
    "    @staticmethod\n",
    "    def train(\n",
    "        data_loader,\n",
    "        model,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler=None,\n",
    "        accumulation_steps=1\n",
    "    ):\n",
    "        \n",
    "        losses = AverageMeter()\n",
    "        predictions = []\n",
    "        model.train()\n",
    "        if accumulation_steps > 1:\n",
    "            optimizer.zero_grad()\n",
    "        #tk0 = tqdm(data_loader, total=len(data_loader), disable=use_tpu)\n",
    "        tk0 = tqdm(data_loader, total=len(data_loader),disable=False)\n",
    "        for b_idx, data in enumerate(tk0):\n",
    "            for key, value in data.items():\n",
    "                data[key] = value.to(device)\n",
    "            if accumulation_steps == 1 and b_idx == 0:\n",
    "                optimizer.zero_grad()\n",
    "            _, loss = model(**data)\n",
    "                   \n",
    "            with torch.set_grad_enabled(True):\n",
    "                loss.backward()\n",
    "                if (b_idx + 1) % accumulation_steps == 0:\n",
    "                    optimizer.step()\n",
    "                    if scheduler is not None:\n",
    "                        scheduler.step()\n",
    "                    if b_idx > 0:\n",
    "                        optimizer.zero_grad()\n",
    "            losses.update(loss.item(), data_loader.batch_size)\n",
    "            tk0.set_postfix(loss=losses.avg)\n",
    "        return losses.avg\n",
    "\n",
    "    @staticmethod\n",
    "    def evaluate(data_loader, model, device):\n",
    "        losses = AverageMeter()\n",
    "        final_predictions = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            #tk0 = tqdm(data_loader, total=len(data_loader), disable=use_tpu)\n",
    "            tk0 = tqdm(data_loader, total=len(data_loader), disable=False)\n",
    "            for b_idx, data in enumerate(tk0):\n",
    "                for key, value in data.items():\n",
    "                    data[key] = value.to(device)\n",
    "                predictions, loss = model(**data)\n",
    "                predictions = predictions.cpu()\n",
    "                losses.update(loss.item(), data_loader.batch_size)\n",
    "                final_predictions.append(predictions)\n",
    "                tk0.set_postfix(loss=losses.avg)\n",
    "        return final_predictions, losses.avg\n",
    "\n",
    "    @staticmethod\n",
    "    def predict(data_loader, model, device, use_tpu=False):\n",
    "        model.eval()\n",
    "        final_predictions = []\n",
    "        with torch.no_grad():\n",
    "            #tk0 = tqdm(data_loader, total=len(data_loader), disable=use_tpu)\n",
    "            tk0 = tqdm(data_loader, total=len(data_loader))\n",
    "            for b_idx, data in enumerate(tk0):\n",
    "                for key, value in data.items():\n",
    "                    data[key] = value.to(device)\n",
    "                predictions, _ = model(**data)\n",
    "                predictions = predictions.cpu()\n",
    "                final_predictions.append(predictions)\n",
    "        return final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(fold):\n",
    "    training_data_path = \"/kaggle/input/siic-isic-224x224-images/train\"\n",
    "    df = df_kfold[df_kfold['kfold']==fold]\n",
    "    device = 'cuda'\n",
    "    epochs = 50\n",
    "    train_bs = 32\n",
    "    val_bs = 16\n",
    "    \n",
    "    df_train = df.loc[df['dataset_type']=='train',list(df_actual_train.columns)]\n",
    "    df_val = df.loc[df['dataset_type']=='val',list(df_actual_train.columns)]\n",
    "    \n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    train_aug = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True,p=1.0)\n",
    "        ]\n",
    "    )\n",
    "    val_aug = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True,p=1.0)\n",
    "        ]\n",
    "    )\n",
    "    train_images_list = df_train.image_name.values.tolist()\n",
    "    train_images = [os.path.join(training_data_path,i + '.png') for i in train_images_list]\n",
    "    train_targets = df_train.target.values\n",
    "    \n",
    "    val_images_list = df_val.image_name.values.tolist()\n",
    "    val_images = [os.path.join(training_data_path,i + '.png') for i in val_images_list]\n",
    "    val_targets = df_val.target.values\n",
    "    \n",
    "    train_dataset = ClassificationLoader(\n",
    "        image_paths = train_images,\n",
    "        targets= train_targets,\n",
    "        resize = None,\n",
    "        augmentations = train_aug\n",
    "    )\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size = train_bs,\n",
    "        shuffle = False,\n",
    "        num_workers=0\n",
    "    )\n",
    "    \n",
    "    val_dataset = ClassificationLoader(\n",
    "        image_paths = val_images,\n",
    "        targets= val_targets,\n",
    "        resize = None,\n",
    "        augmentations = val_aug\n",
    "    )\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size = val_bs,\n",
    "        shuffle = False,\n",
    "        num_workers=0\n",
    "    )\n",
    "    #Earlier defined class for model\n",
    "    #model = Model_Inception_v3(pretrained='imagenet')\n",
    "    model = Model_ResNext_Pytorch(pretrained=True)\n",
    "    model.to(device)\n",
    "    \n",
    "    #Specify an optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    \n",
    "    #Specify an scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        patience=3,\n",
    "        mode='max'\n",
    "    )\n",
    "    # why mode='max' becauase we will be using the metric of AUC\n",
    "    \n",
    "    # we would also need early stopping\n",
    "    es = EarlyStopping(patience=5, mode='max')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        training_loss = Engine.train(\n",
    "            train_loader,\n",
    "            model,\n",
    "            optimizer,\n",
    "            device\n",
    "        )\n",
    "        predictions, val_loss = Engine.evaluate(\n",
    "            val_loader,\n",
    "            model,\n",
    "            device\n",
    "        )\n",
    "        \n",
    "        predictions = np.vstack((predictions)).ravel()\n",
    "        # Ravel it because we have only one value\n",
    "        auc = metrics.roc_auc_score(val_targets, predictions)\n",
    "        # thats why val_loader shuffle was kept false\n",
    "        \n",
    "        scheduler.step(auc)\n",
    "        print(f\"epoch={epoch},auc={auc}\")\n",
    "        # Save it with .bin extension\n",
    "        model_path = f'model_fold{fold}_epoch{epoch}'\n",
    "        es(auc, model, model_path)\n",
    "        if es.early_stop:\n",
    "            print(\"Early Stopping\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(fold=0):\n",
    "    test_data_path = \"/kaggle/input/siic-isic-224x224-images/test\"\n",
    "    df_test = pd.read_csv(\"/kaggle/input/siim-isic-melanoma-classification/test.csv\")\n",
    "    df_test.loc[:,'target'] = 0\n",
    "    \n",
    "    #model_path = \"f'/kaggle/working/model_fold{fold}'\"\n",
    "    model_path = '/kaggle/working/model_fold0_epoch0'\n",
    "    \n",
    "    device = 'cuda'\n",
    "    epochs = 50\n",
    "    test_bs = 16\n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    test_aug = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True,p=1.0)\n",
    "        ]\n",
    "    )\n",
    "    test_images_list = df_test.image_name.values.tolist()\n",
    "    test_images = [os.path.join(test_data_path,i + '.png') for i in test_images_list]\n",
    "    test_targets = df_test.target.values\n",
    "    \n",
    "    test_dataset = ClassificationLoader(\n",
    "        image_paths = test_images,\n",
    "        targets= test_targets,\n",
    "        resize = None,\n",
    "        augmentations = test_aug\n",
    "    )\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size = test_bs,\n",
    "        shuffle = False,\n",
    "        num_workers=4\n",
    "    )\n",
    "    #Earlier defined class for model\n",
    "    model = Model_ResNext_Pytorch(pretrained=True)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "    \n",
    "    predictions_op = Engine.predict(\n",
    "        test_loader,\n",
    "        model,\n",
    "        device\n",
    "    )\n",
    "    return np.vstack((predictions_op)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/archive/v0.6.0.zip\" to /root/.cache/torch/hub/v0.6.0.zip\n",
      "Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /root/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3e53106dc04ad9a83b3f6997e2dc00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=100441675.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 932/932 [08:55<00:00,  1.74it/s, loss=0.0858]\n",
      "100%|██████████| 208/208 [00:30<00:00,  6.72it/s, loss=0.0617]\n",
      "  0%|          | 0/932 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0,auc=0.8714777947932619\n",
      "Validation score improved (-inf --> 0.8714777947932619). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 932/932 [07:50<00:00,  1.98it/s, loss=0.0676]\n",
      "100%|██████████| 208/208 [00:24<00:00,  8.66it/s, loss=0.0585]\n",
      "  0%|          | 0/932 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1,auc=0.888571975497703\n",
      "Validation score improved (0.8714777947932619 --> 0.888571975497703). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 260/932 [02:12<05:41,  1.96it/s, loss=0.0666]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-89ee0a5f6e60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-9f74fa2d57af>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(fold)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         )\n\u001b[1;32m     85\u001b[0m         predictions, val_loss = Engine.evaluate(\n",
      "\u001b[0;32m<ipython-input-11-06b4f7ceb2d6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_loader, model, optimizer, device, scheduler, accumulation_steps)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mb_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccumulation_steps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(fold=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating submission.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n",
      "100%|██████████| 687/687 [00:49<00:00, 13.86it/s]\n"
     ]
    }
   ],
   "source": [
    "pred = predict()\n",
    "sample = pd.read_csv(\"../input/siim-isic-melanoma-classification/sample_submission.csv\")\n",
    "sample.loc[:, \"target\"] = pred\n",
    "sample.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
